{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time, sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate all the functions\n",
    "stopnltk = set(stopwords.words('indonesian'))\n",
    "factory = StopWordRemoverFactory()\n",
    "stopsastrawi = factory.get_stop_words()\n",
    "stemfactory = StemmerFactory()\n",
    "stemmer = stemfactory.create_stemmer()\n",
    "tf = TfidfVectorizer()\n",
    "mnb = MultinomialNB() #multinomial naive bayes classifier\n",
    "mlp = MLPClassifier(alpha=1, max_iter=2000) #MLP classifier\n",
    "clf = svm.SVC(gamma='scale') #SVM classifier\n",
    "smt = SMOTE()\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open pickle files 'train.pkl' and 'test.pkl', and then assign the result to train and test respectively\n",
    "with open('train.pkl', 'rb') as a:\n",
    "    train = pickle.load(a)\n",
    "    \n",
    "with open('test.pkl', 'rb') as b:\n",
    "    test = pickle.load(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new feature called word_count to see how many words that each document has within train set\n",
    "train['word_count'] = train['RESPONSE'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3392.000000</td>\n",
       "      <td>3392.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.074882</td>\n",
       "      <td>18.858196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.263240</td>\n",
       "      <td>7.294067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>174.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LABEL   word_count\n",
       "count  3392.000000  3392.000000\n",
       "mean      0.074882    18.858196\n",
       "std       0.263240     7.294067\n",
       "min       0.000000     1.000000\n",
       "25%       0.000000    14.000000\n",
       "50%       0.000000    19.000000\n",
       "75%       0.000000    24.000000\n",
       "max       1.000000   174.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check basic statistic of train set\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESPONSE</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>alia sedang mengerjakan sebuah laporan tentang...</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              RESPONSE  LABEL  word_count\n",
       "199  alia sedang mengerjakan sebuah laporan tentang...      0         174"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#as we can see on the prev. cell that the max words is at 174 words while the average words within train is 19 words.\n",
    "#we can consider this as outlier. First, take a look at how many docs have words more that 100\n",
    "train[train['word_count'] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after we found it, then remove 'em all\n",
    "train = train.drop(index=199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word processing\n",
    "\n",
    "target = []\n",
    "alphanum = re.compile(r\"[^a-zA-Z ]\")\n",
    "\n",
    "train['RESPONSE'] = train['RESPONSE'].astype('str')\n",
    "for i in train['RESPONSE']:\n",
    "    i = i.lower() #unification\n",
    "    i = re.sub(alphanum, ' ', i) #remove non alpha-num chars\n",
    "    i = re.sub('[\\s]+', ' ', i) #remove additional whitespaces\n",
    "    target.append(i)\n",
    "    \n",
    "train['RESPONSE'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords removal. We use NLTK instead of Sastrawi because NLTK has more words than Sastrawi.\n",
    "\n",
    "target = []\n",
    "for i in train['RESPONSE']:\n",
    "    filtered_sentence = [w for w in i.split() if not w in stopnltk]\n",
    "    i = ' '.join(filtered_sentence)\n",
    "    target.append(i)\n",
    "    \n",
    "train['RESPONSE'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new feature called word_count_wo_stopword to see how many words that each document has within train set,\n",
    "#after stop word removal.\n",
    "train['word_count_wo_stopword'] = train['RESPONSE'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_wo_stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3391.000000</td>\n",
       "      <td>3391.000000</td>\n",
       "      <td>3391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.074904</td>\n",
       "      <td>18.812445</td>\n",
       "      <td>13.885579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.263275</td>\n",
       "      <td>6.790952</td>\n",
       "      <td>5.546415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LABEL   word_count  word_count_wo_stopword\n",
       "count  3391.000000  3391.000000             3391.000000\n",
       "mean      0.074904    18.812445               13.885579\n",
       "std       0.263275     6.790952                5.546415\n",
       "min       0.000000     1.000000                0.000000\n",
       "25%       0.000000    14.000000               10.000000\n",
       "50%       0.000000    19.000000               14.000000\n",
       "75%       0.000000    24.000000               18.000000\n",
       "max       1.000000    89.000000               49.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove observations that have words less than 3.\n",
    "drop = train[train['word_count_wo_stopword'] < 3]\n",
    "dr = []\n",
    "for i in drop.iterrows():\n",
    "    dr.append(i[0])\n",
    "    \n",
    "train = train.drop(index=dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_wo_stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3325.000000</td>\n",
       "      <td>3325.000000</td>\n",
       "      <td>3325.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.066767</td>\n",
       "      <td>19.090827</td>\n",
       "      <td>14.132331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.249655</td>\n",
       "      <td>6.550566</td>\n",
       "      <td>5.313736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LABEL   word_count  word_count_wo_stopword\n",
       "count  3325.000000  3325.000000             3325.000000\n",
       "mean      0.066767    19.090827               14.132331\n",
       "std       0.249655     6.550566                5.313736\n",
       "min       0.000000     3.000000                3.000000\n",
       "25%       0.000000    14.000000               10.000000\n",
       "50%       0.000000    19.000000               14.000000\n",
       "75%       0.000000    24.000000               18.000000\n",
       "max       1.000000    89.000000               49.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process time: 32.232s\n"
     ]
    }
   ],
   "source": [
    "#stemming\n",
    "\n",
    "target = []\n",
    "t0 = time()\n",
    "for i in train['RESPONSE']:\n",
    "    i = stemmer.stem(i)\n",
    "    target.append(i)\n",
    "\n",
    "process_time = time() - t0\n",
    "print(\"Process time: %0.3fs\" % process_time)\n",
    "train['RESPONSE'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (2227,)\n",
      "Testing:  (1098,)\n"
     ]
    }
   ],
   "source": [
    "#split the data into 2 sets. train, and test.\n",
    "response_tr, response_te, label_tr, label_te = train_test_split(train.RESPONSE, train.LABEL, stratify=train.LABEL, test_size=0.33)\n",
    "print(\"Training: \",response_tr.shape)\n",
    "print(\"Testing: \",response_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer the documents using tf-idf\n",
    "Xtr = tf.fit_transform(response_tr)\n",
    "Xte = tf.transform(response_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2227, 531)\n",
      "(1098, 531)\n"
     ]
    }
   ],
   "source": [
    "print(Xtr.shape)\n",
    "print(Xte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      1025\n",
      "           1       0.00      0.00      0.00        73\n",
      "\n",
      "    accuracy                           0.93      1098\n",
      "   macro avg       0.47      0.50      0.48      1098\n",
      "weighted avg       0.87      0.93      0.90      1098\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#fit and predict using MNB classifier.\n",
    "mnb.fit(Xtr, label_tr)\n",
    "pred = mnb.predict(Xte)\n",
    "print(classification_report(label_te, pred, target_names=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the accuracy is good but precision, recall, and f1-score for class 1 is not good. This is because the imbalance dataset that we have. Let's see the next classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1025\n",
      "           1       0.87      0.45      0.59        73\n",
      "\n",
      "    accuracy                           0.96      1098\n",
      "   macro avg       0.92      0.72      0.79      1098\n",
      "weighted avg       0.96      0.96      0.95      1098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit and predict using SVM classifier.\n",
    "clf.fit(Xtr, label_tr)\n",
    "predSVM = clf.predict(Xte)\n",
    "print(classification_report(label_te, predSVM, target_names=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM shows better accuracy, better precision, but still low in term of recall score. This means the model can’t detect the class well but is highly trustable when it does. We won't let it happen. Let's see next classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1025\n",
      "           1       1.00      0.05      0.10        73\n",
      "\n",
      "    accuracy                           0.94      1098\n",
      "   macro avg       0.97      0.53      0.54      1098\n",
      "weighted avg       0.94      0.94      0.91      1098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit and predict using MLP classifier.\n",
    "mlp.fit(Xtr, label_tr)\n",
    "predMLP = mlp.predict(Xte)\n",
    "print(classification_report(label_te, predMLP, target_names=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP shows the same accuracy as SVM does. However, precision for class 1 is increased slightly. Again, this is because an imbalance dataset. Let's see the distribution of our train set label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3103\n",
       "1     222\n",
       "Name: LABEL, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.LABEL.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clearly see that the distribution between class 1 and 0 is imbalance. This is why the model get high accuracy but low on recall for class 1. \n",
    "\n",
    "We can deal with imbalance data set with SMOTE (Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resampling dataset to deal with imbalance class\n",
    "\n",
    "X_train, y_train = smt.fit_sample(Xtr, label_tr)\n",
    "X_test, y_test = smt.fit_sample(Xte, label_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2078, 2078])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the same size of class 1 and 0. Let's then try to feed the new balance data to the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90      1025\n",
      "           1       0.96      0.82      0.89      1025\n",
      "\n",
      "    accuracy                           0.90      2050\n",
      "   macro avg       0.90      0.90      0.89      2050\n",
      "weighted avg       0.90      0.90      0.89      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit and predict using MNB classifier with balance dataset\n",
    "mnb.fit(X_train, y_train)\n",
    "predMNBSmote = mnb.predict(X_test)\n",
    "print(classification_report(y_test, predMNBSmote, target_names=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparing with the previous result of MNB, this accuracy is below the previous one. But the precision, recall, and f1-score show that the data is handled well by the model. Let's try for SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      1025\n",
      "           1       0.99      0.81      0.89      1025\n",
      "\n",
      "    accuracy                           0.90      2050\n",
      "   macro avg       0.91      0.90      0.90      2050\n",
      "weighted avg       0.91      0.90      0.90      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit and predict using SVM classifier with balance dataset\n",
    "clf.fit(X_train, y_train)\n",
    "predSVMSMOTE = clf.predict(X_test)\n",
    "print(classification_report(y_test, predSVMSMOTE, target_names=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM with balanced dataset shows better performance that MNB above. Let's see the last one. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1025\n",
      "           1       0.95      0.87      0.91      1025\n",
      "\n",
      "    accuracy                           0.91      2050\n",
      "   macro avg       0.92      0.91      0.91      2050\n",
      "weighted avg       0.92      0.91      0.91      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit and predict using MLP classifier with balance dataset\n",
    "mlp.fit(X_train, y_train)\n",
    "predMLPSMOTE = mlp.predict(X_test)\n",
    "print(classification_report(y_test, predMLPSMOTE, target_names=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[979,  46],\n",
       "       [132, 893]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confussion matrix of the model that has highest accuracy\n",
    "labels = ['0', '1']\n",
    "cm = confusion_matrix(y_test, predMLPSMOTE)\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, cmap='Reds', ax=ax)\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix') \n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline is 90%, so accuracy 91 is just too close with base line. I try to adjust things, and that is to change the vectorizer. Above methods are used tf-idf as word vectorizer. Try change it to bag of word and let's see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer the documents using bag of word\n",
    "Xtr = count_vect.fit_transform(response_tr)\n",
    "Xte = count_vect.transform(response_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2227, 533)\n",
      "(1098, 533)\n"
     ]
    }
   ],
   "source": [
    "print(Xtr.shape)\n",
    "print(Xte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the sake of simplicity, we are going to jump directly to SMOTE\n",
    "#resampling dataset to deal with imbalance class\n",
    "\n",
    "X_train, y_train = smt.fit_sample(Xtr, label_tr)\n",
    "X_test, y_test = smt.fit_sample(Xte, label_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93      1025\n",
      "           1       0.98      0.87      0.92      1025\n",
      "\n",
      "    accuracy                           0.93      2050\n",
      "   macro avg       0.93      0.93      0.93      2050\n",
      "weighted avg       0.93      0.93      0.93      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit and predict using MNB classifier with balance dataset and bag of words\n",
    "mnb.fit(X_train, y_train)\n",
    "predMNBSmote = mnb.predict(X_test)\n",
    "print(classification_report(y_test, predMNBSmote, target_names=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first run, we get higher measurement among all the classifiers with tf-idf. Let's see for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1025\n",
      "           1       0.98      0.96      0.97      1025\n",
      "\n",
      "    accuracy                           0.97      2050\n",
      "   macro avg       0.97      0.97      0.97      2050\n",
      "weighted avg       0.97      0.97      0.97      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit and predict using SVM classifier with balance dataset and bag of words\n",
    "clf.fit(X_train, y_train)\n",
    "predSVMSMOTE = clf.predict(X_test)\n",
    "print(classification_report(y_test, predSVMSMOTE, target_names=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM outperform MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1025\n",
      "           1       0.96      0.98      0.97      1025\n",
      "\n",
      "    accuracy                           0.97      2050\n",
      "   macro avg       0.97      0.97      0.97      2050\n",
      "weighted avg       0.97      0.97      0.97      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit and predict using MLP classifier with balance dataset and bag of words\n",
    "mlp.fit(X_train, y_train)\n",
    "predMLPSMOTE = mlp.predict(X_test)\n",
    "print(classification_report(y_test, predMLPSMOTE, target_names=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because SVM and MLP have the same score, we are going to use them to predict label from test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model using test set\n",
    "Xtarget = count_vect.transform(test.RESPONSE)\n",
    "\n",
    "resultSVM = clf.predict(Xtarget)\n",
    "\n",
    "resultMLP = mlp.predict(Xtarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['LABEL_SVM'] = resultSVM\n",
    "test['LABEL_MLP'] = resultMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('TEST_WITH_LABEL.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
