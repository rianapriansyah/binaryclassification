{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time, sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate all the functions\n",
    "stopnltk = set(stopwords.words('indonesian'))\n",
    "factory = StopWordRemoverFactory()\n",
    "stopsastrawi = factory.get_stop_words()\n",
    "stemfactory = StemmerFactory()\n",
    "stemmer = stemfactory.create_stemmer()\n",
    "tf = TfidfVectorizer()\n",
    "mnb = MultinomialNB() #multinomial naive bayes classifier\n",
    "mlp = MLPClassifier(alpha=1, max_iter=2000) #MLP classifier\n",
    "clf = svm.SVC(gamma='scale') #SVM classifier\n",
    "smt = SMOTE()\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open pickle files 'train.pkl' and 'test.pkl', and then assign the result to train and test respectively\n",
    "with open('train.pkl', 'rb') as a:\n",
    "    train = pickle.load(a)\n",
    "    \n",
    "with open('test.pkl', 'rb') as b:\n",
    "    test = pickle.load(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new feature called word_count to see how many words that each document has within train set\n",
    "train['word_count'] = train['RESPONSE'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3392.000000</td>\n",
       "      <td>3392.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.074882</td>\n",
       "      <td>18.858196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.263240</td>\n",
       "      <td>7.294067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>174.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LABEL   word_count\n",
       "count  3392.000000  3392.000000\n",
       "mean      0.074882    18.858196\n",
       "std       0.263240     7.294067\n",
       "min       0.000000     1.000000\n",
       "25%       0.000000    14.000000\n",
       "50%       0.000000    19.000000\n",
       "75%       0.000000    24.000000\n",
       "max       1.000000   174.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check basic statistic of train set\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESPONSE</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>alia sedang mengerjakan sebuah laporan tentang...</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              RESPONSE  LABEL  word_count\n",
       "199  alia sedang mengerjakan sebuah laporan tentang...      0         174"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#as we can see on the prev. cell that the max words is at 174 words while the average words within train is 19 words.\n",
    "#we can consider this as outlier. First, take a look at how many docs have words more that 100\n",
    "train[train['word_count'] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after we found it, then remove 'em all\n",
    "train = train.drop(index=199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word processing\n",
    "\n",
    "target = []\n",
    "alphanum = re.compile(r\"[^a-zA-Z ]\")\n",
    "\n",
    "train['RESPONSE'] = train['RESPONSE'].astype('str')\n",
    "for i in train['RESPONSE']:\n",
    "    i = i.lower() #unification\n",
    "    i = re.sub(alphanum, ' ', i) #remove non alpha-num chars\n",
    "    i = re.sub('[\\s]+', ' ', i) #remove additional whitespaces\n",
    "    target.append(i)\n",
    "    \n",
    "train['RESPONSE'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords removal. We use NLTK instead of Sastrawi because NLTK has more words than Sastrawi.\n",
    "\n",
    "target = []\n",
    "for i in train['RESPONSE']:\n",
    "    filtered_sentence = [w for w in i.split() if not w in stopnltk]\n",
    "    i = ' '.join(filtered_sentence)\n",
    "    target.append(i)\n",
    "    \n",
    "train['RESPONSE'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new feature called word_count_wo_stopword to see how many words that each document has within train set,\n",
    "#after stop word removal.\n",
    "train['word_count_wo_stopword'] = train['RESPONSE'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_wo_stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3391.000000</td>\n",
       "      <td>3391.000000</td>\n",
       "      <td>3391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.074904</td>\n",
       "      <td>18.812445</td>\n",
       "      <td>13.885579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.263275</td>\n",
       "      <td>6.790952</td>\n",
       "      <td>5.546415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LABEL   word_count  word_count_wo_stopword\n",
       "count  3391.000000  3391.000000             3391.000000\n",
       "mean      0.074904    18.812445               13.885579\n",
       "std       0.263275     6.790952                5.546415\n",
       "min       0.000000     1.000000                0.000000\n",
       "25%       0.000000    14.000000               10.000000\n",
       "50%       0.000000    19.000000               14.000000\n",
       "75%       0.000000    24.000000               18.000000\n",
       "max       1.000000    89.000000               49.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove observations that have words less than 3.\n",
    "drop = train[train['word_count_wo_stopword'] < 3]\n",
    "dr = []\n",
    "for i in drop.iterrows():\n",
    "    dr.append(i[0])\n",
    "    \n",
    "train = train.drop(index=dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_wo_stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3325.000000</td>\n",
       "      <td>3325.000000</td>\n",
       "      <td>3325.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.066767</td>\n",
       "      <td>19.090827</td>\n",
       "      <td>14.132331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.249655</td>\n",
       "      <td>6.550566</td>\n",
       "      <td>5.313736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LABEL   word_count  word_count_wo_stopword\n",
       "count  3325.000000  3325.000000             3325.000000\n",
       "mean      0.066767    19.090827               14.132331\n",
       "std       0.249655     6.550566                5.313736\n",
       "min       0.000000     3.000000                3.000000\n",
       "25%       0.000000    14.000000               10.000000\n",
       "50%       0.000000    19.000000               14.000000\n",
       "75%       0.000000    24.000000               18.000000\n",
       "max       1.000000    89.000000               49.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process time: 32.232s\n"
     ]
    }
   ],
   "source": [
    "#stemming\n",
    "\n",
    "target = []\n",
    "t0 = time()\n",
    "for i in train['RESPONSE']:\n",
    "    i = stemmer.stem(i)\n",
    "    target.append(i)\n",
    "\n",
    "process_time = time() - t0\n",
    "print(\"Process time: %0.3fs\" % process_time)\n",
    "train['RESPONSE'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (2227,)\n",
      "Testing:  (1098,)\n"
     ]
    }
   ],
   "source": [
    "#split the data into 2 sets. train, and test.\n",
    "response_tr, response_te, label_tr, label_te = train_test_split(train.RESPONSE, train.LABEL, stratify=train.LABEL, test_size=0.33)\n",
    "print(\"Training: \",response_tr.shape)\n",
    "print(\"Testing: \",response_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer the documents using tf-idf\n",
    "Xtr = tf.fit_transform(response_tr)\n",
    "Xte = tf.transform(response_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2227, 531)\n",
      "(1098, 531)\n"
     ]
    }
   ],
   "source": [
    "print(Xtr.shape)\n",
    "print(Xte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      1025\n",
      "           1       0.00      0.00      0.00        73\n",
      "\n",
      "    accuracy                           0.93      1098\n",
      "   macro avg       0.47      0.50      0.48      1098\n",
      "weighted avg       0.87      0.93      0.90      1098\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#fit and predict using MNB classifier.\n",
    "mnb.fit(Xtr, label_tr)\n",
    "pred = mnb.predict(Xte)\n",
    "print(classification_report(label_te, pred, target_names=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the accuracy is good but precision, recall, and f1-score for class 1 is not good. This is because the imbalance dataset that we have. Let's see the next classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1025\n",
      "           1       0.87      0.45      0.59        73\n",
      "\n",
      "    accuracy                           0.96      1098\n",
      "   macro avg       0.92      0.72      0.79      1098\n",
      "weighted avg       0.96      0.96      0.95      1098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit and predict using SVM classifier.\n",
    "clf.fit(Xtr, label_tr)\n",
    "predSVM = clf.predict(Xte)\n",
    "print(classification_report(label_te, predSVM, target_names=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM shows better accuracy, better precision, but still low in term of recall score. This means the model canâ€™t detect the class well but is highly trustable when it does. We won't let it happen. Let's see next classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1025\n",
      "           1       1.00      0.05      0.10        73\n",
      "\n",
      "    accuracy                           0.94      1098\n",
      "   macro avg       0.97      0.53      0.54      1098\n",
      "weighted avg       0.94      0.94      0.91      1098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit and predict using MLP classifier.\n",
    "mlp.fit(Xtr, label_tr)\n",
    "predMLP = mlp.predict(Xte)\n",
    "print(classification_report(label_te, predMLP, target_names=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP shows the same accuracy as SVM does. However, precision for class 1 is increased slightly. Again, this is because an imbalance dataset. Let's see the distribution of our train set label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3103\n",
       "1     222\n",
       "Name: LABEL, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.LABEL.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clearly see that the distribution between class 1 and 0 is imbalance. This is why the model get high accuracy but low on recall for class 1. \n",
    "\n",
    "We can deal with imbalance data set with SMOTE (Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resampling dataset to deal with imbalance class\n",
    "\n",
    "X_train, y_train = smt.fit_sample(Xtr, label_tr)\n",
    "X_test, y_test = smt.fit_sample(Xte, label_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2078, 2078])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the same size of class 1 and 0. Let's then try to feed the new balance data to the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90      1025\n",
      "           1       0.96      0.82      0.89      1025\n",
      "\n",
      "    accuracy                           0.90      2050\n",
      "   macro avg       0.90      0.90      0.89      2050\n",
      "weighted avg       0.90      0.90      0.89      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit and predict using MNB classifier with balance dataset\n",
    "mnb.fit(X_train, y_train)\n",
    "predMNBSmote = mnb.predict(X_test)\n",
    "print(classification_report(y_test, predMNBSmote, target_names=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparing with the previous result of MNB, this accuracy is below the previous one. But the precision, recall, and f1-score show that the data is handled well by the model. Let's try for SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      1025\n",
      "           1       0.99      0.81      0.89      1025\n",
      "\n",
      "    accuracy                           0.90      2050\n",
      "   macro avg       0.91      0.90      0.90      2050\n",
      "weighted avg       0.91      0.90      0.90      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit and predict using SVM classifier with balance dataset\n",
    "clf.fit(X_train, y_train)\n",
    "predSVMSMOTE = clf.predict(X_test)\n",
    "print(classification_report(y_test, predSVMSMOTE, target_names=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM with balanced dataset shows better performance that MNB above. Let's see the last one. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1025\n",
      "           1       0.95      0.87      0.91      1025\n",
      "\n",
      "    accuracy                           0.91      2050\n",
      "   macro avg       0.92      0.91      0.91      2050\n",
      "weighted avg       0.92      0.91      0.91      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit and predict using MLP classifier with balance dataset\n",
    "mlp.fit(X_train, y_train)\n",
    "predMLPSMOTE = mlp.predict(X_test)\n",
    "print(classification_report(y_test, predMLPSMOTE, target_names=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[979,  46],\n",
       "       [132, 893]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confussion matrix of the model that has highest accuracy\n",
    "labels = ['0', '1']\n",
    "cm = confusion_matrix(y_test, predMLPSMOTE)\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, cmap='Reds', ax=ax)\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix') \n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline is 90%, so accuracy 91 is just too close with base line. I try to adjust things, and that is to change the vectorizer. Above methods are used tf-idf as word vectorizer. Try change it to bag of word and let's see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer the documents using bag of word\n",
    "Xtr = count_vect.fit_transform(response_tr)\n",
    "Xte = count_vect.transform(response_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2227, 533)\n",
      "(1098, 533)\n"
     ]
    }
   ],
   "source": [
    "print(Xtr.shape)\n",
    "print(Xte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the sake of simplicity, we are going to jump directly to SMOTE\n",
    "#resampling dataset to deal with imbalance class\n",
    "\n",
    "X_train, y_train = smt.fit_sample(Xtr, label_tr)\n",
    "X_test, y_test = smt.fit_sample(Xte, label_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93      1025\n",
      "           1       0.98      0.87      0.92      1025\n",
      "\n",
      "    accuracy                           0.93      2050\n",
      "   macro avg       0.93      0.93      0.93      2050\n",
      "weighted avg       0.93      0.93      0.93      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit and predict using MNB classifier with balance dataset and bag of words\n",
    "mnb.fit(X_train, y_train)\n",
    "predMNBSmote = mnb.predict(X_test)\n",
    "print(classification_report(y_test, predMNBSmote, target_names=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first run, we get higher measurement among all the classifiers with tf-idf. Let's see for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1025\n",
      "           1       0.98      0.96      0.97      1025\n",
      "\n",
      "    accuracy                           0.97      2050\n",
      "   macro avg       0.97      0.97      0.97      2050\n",
      "weighted avg       0.97      0.97      0.97      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit and predict using SVM classifier with balance dataset and bag of words\n",
    "clf.fit(X_train, y_train)\n",
    "predSVMSMOTE = clf.predict(X_test)\n",
    "print(classification_report(y_test, predSVMSMOTE, target_names=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM outperform MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1025\n",
      "           1       0.96      0.98      0.97      1025\n",
      "\n",
      "    accuracy                           0.97      2050\n",
      "   macro avg       0.97      0.97      0.97      2050\n",
      "weighted avg       0.97      0.97      0.97      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit and predict using MLP classifier with balance dataset and bag of words\n",
    "mlp.fit(X_train, y_train)\n",
    "predMLPSMOTE = mlp.predict(X_test)\n",
    "print(classification_report(y_test, predMLPSMOTE, target_names=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because SVM and MLP have the same score, we are going to use them to predict label from test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model using test set\n",
    "Xtarget = count_vect.transform(test.RESPONSE)\n",
    "\n",
    "resultSVM = clf.predict(Xtarget)\n",
    "\n",
    "resultMLP = mlp.predict(Xtarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['LABEL_SVM'] = resultSVM\n",
    "test['LABEL_MLP'] = resultMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('TEST_WITH_LABEL.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
